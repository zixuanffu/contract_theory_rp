\documentclass[12pt]{article}
\usepackage{fullpage,graphicx,psfrag,amsmath,amsfonts,verbatim}
\usepackage[small,bf]{caption}
\usepackage{amsthm}
% \usepackage[hidelinks]{hyperref}
\usepackage{hyperref}
\usepackage{bbm} % for the indicator function to look good
\usepackage{color}
\usepackage{mathtools}
\usepackage{fancyhdr} % for the header
\usepackage{booktabs} % for regression table display (toprule, midrule, bottomrule)
\usepackage{adjustbox} % for regression table display
\usepackage{threeparttable} % to use table notes
\usepackage{natbib} % for bibliography
\usepackage{tikz}
\usetikzlibrary{arrows.meta}
\input newcommand.tex
% \renewcommand{\thesubsection}{} 
\bibliographystyle{apalike}
% \setlength{\parindent}{0pt} % remove the automatic indentation

\title{Exploring blinding in peer review system}
\author{Fu Zixuan \\{\small {Research proposal}}}
\date{\today}

\begin{document}
\maketitle
% \thispagestyle{empty}
% \begin{abstract}

% \end{abstract}

% \newpage
% \thispagestyle{empty}
% \tableofcontents
% \newpage

% \setcounter{page}{1}

\section{Introduction}
% \begin{quote}
%     An eye for an eye, makes the whole world blind.
% \end{quote}
I always find it intriguing, and perhaps disheartening, that in some fields of
research, it takes several years, even up to a decade, for a paper to be
published. The publication cycle varies greatly across disciplines and venues,
ranging from computer science conferences to economics journals
\cite{hadavand2024publishing}. One crucial step in the publication process is
the widely adopted peer review system, which serves as the gatekeeper for the
profession. Delays in this process can stem from late submission of referee
reports, authors postponing revisions, or even editors delaying the assignment
of papers for review or publication. At first glance, the idea of peer review
seems straightforward, but it encompasses numerous dimensions and
configurations \cite{soergel2013open}. This complexity motivates me to examine
one specific aspect of it—the degree of blinding or anonymity. Table
\ref{tab:review_mechanism} illustrates the different anonymity configurations
in peer review mechanisms.

\begin{table}[h!]
    \centering
    \begin{tabular}{lcc}
        \toprule
        \textbf{Authors}    & \multicolumn{2}{c}{\textbf{Reviewers}}                       \\ \cmidrule(lr){2-3}
                            & \textbf{Anonymized}                    & \textbf{Identified} \\ \midrule
        \textbf{Anonymized} & Double blind                           & x                   \\
        \textbf{Identified} & Single blind                           & Open review         \\ \bottomrule
    \end{tabular}
    \caption{Review mechanisms based on the anonymity of authors and reviewers.}
    \label{tab:review_mechanism}
\end{table}

In 2003, \citet{bachand2003accuracy} conducted a survey of 554 journals across
18 disciplines, finding that 58\% of journals use double-blind reviews, 37\%
single-blind, and only 5\% open peer review. However, a journal's decision on
the review mechanism is not static. For instance, as documented by
\citet{pontille2014blind}, the American Economic Review (AER) has alternated
between single- and double-blind reviews multiple times from 1973 to 2011. A
clear pattern emerges where specific fields exhibit a preference for one system
over another, with advocates and opponents offering compelling reasons for
their positions.

\begin{quote}
    The move to single-blind refereeing (where referees’ identities remain undisclosed) is effective from July 1, 2011. Easy access to search engines increasingly limits the effectiveness of the double-blind process in maintaining anonymity. Further, it increases the administrative cost of the journals and makes it harder for referees to identify an author's potential conflicts of interest arising, for example, from consulting \citep{AER2011}.
\end{quote}

In double-blind reviews, neither authors nor reviewers know each other’s
identities during the review process. This system is designed to eliminate
potential biases related to the author’s affiliation or reputation and to
enable reviewers to provide honest feedback without fear of retaliation. In
single-blind reviews, authors’ identities are revealed to reviewers, but
reviewers remain anonymous.

Advocates of more transparent practices have called for open review systems,
where all identities are revealed, and feedback is made publicly accessible to
enhance accountability and fairness. However, double- and single-blind reviews
remain the norm in scientific research.

Anonymity also influences reviewer behavior. Anecdotal evidence suggests that
some reviewers may prefer knowing the authors’ identities, as it allows them to
form prior beliefs about the paper’s quality based on the authors’ reputations.
These priors can help reviewers allocate their time more efficiently—for
example, by focusing less on verifying technical details if the author has a
strong publication track record. This raises important questions about how such
heuristics impact the review process and whether they align with the goal of
ensuring high-quality, unbiased reviews.

The peer review system has two main objectives: to screen out bad science from
being published and to help authors improve the quality of their paper before
publication \citep{tan2018peer}. In this paper, I focus only on the first
function—discovering the true quality of the paper. The journal editor aims to
maximize welfare by accepting high-quality papers and rejecting poor ones.
However, the task of evaluating submissions is delegated to reviewers, whose
effort levels and biases can influence the accuracy of their recommendations.
To simplify the analysis, I limit the scope to binary cases of paper quality
and author type.

The next section introduces the field of research on research itself, known as
\textit{journalology}, along with some empirical evidence and theoretical
explanations. Section \ref{sec:model} formalizes the intuition presented here.
Section \ref{sec:analysis} provides a preliminary analysis of the factors
influencing a journal's choices. The final section discusses issues
deliberately ignored or overlooked in the earlier sections.

\section{Related Literature}
There is a large body of literature on the topic of peer review, upon which a
new scientific field, \textit{journalology}, has been built.

Many empirical studies focus on detecting bias, evaluating fairness, and
measuring the quality of peer review under different blinding mechanisms,
notably single-blind and double-blind. Interestingly, as summarized in the book
chapter by \citet{largent2016blind}, experimental and statistical results are
divided. Even now, there is no consensus on the effects or non-effects of peer
review practices \cite{blank1991effects,tomkins2017reviewer}.

\citet{tan2018peer} provides a summary of the strengths and weaknesses of different referee practices. For example, single-blind reviews may result in reviewers favoring well-known authors compared to double-blind reviews, where identifying information about the authors is removed. However, double-blind reviews raise questions about true anonymity and the additional cost of preparing papers for such reviews. \citet{snodgrass2007single} identifies six benefits of double-blind review compared to 21 potential costs, while noting that complete masking of authorship is often infeasible in practice. Some researchers advocate for a more open process with varying degrees of transparency, ranging from open feedback to open reviewer identity. Unsurprisingly, concerns arise from all sides (editor, reviewer, author) about the implications of maximal openness in the review process. In this context, I particularly appreciate the project by \citet{soergel2013open}, which led to the creation of the platform \href{https://openreview.net/}{OpenReview.net}. This platform supports a variety of configurations, enabling journals and conferences to experiment with different dimensions of open scholarship.\footnote{\textit{"The word 'open' denotes access to information. To characterize a system, then, we must state who has access to what information and when. (Additionally, there may be special conditions on that access)."}}

Finally, since peer review is not discipline-specific, studies approach it from
diverse angles. From an economic theory perspective, I was first inspired by
the work of \citet{garcia2015principal}, which proposes a reward system for
reviewers under a moral hazard framework where the editor is the principal and
the reviewer is the agent. Other works examine the interplay between reviewers
and editors \citep{garcia2021interplay}, authors and editors
\citep{garcia2022fraud}, and authors and reviewers
\citep{radzvilas2023incentives}. Much of this research is published in the
journal \textit{Scientometrics}, which is dedicated to the study of scholarly
literature. It is fascinating to observe how economic theories are applied in
such a concrete setting.

Drawing on the relevant literature, I base my model on empirical evidence
showing that the most commonly used peer review mechanisms are single-blind and
double-blind. Consequently, I study only the editor's binary choice of
mechanism. Furthermore, since no consensus exists on which mechanism is
superior, I assume that journals make their decisions based on the specific
needs of their discipline. Although I recognize the principal-agent nature of
this setting, I do not model the classical adverse selection or moral hazard
problems. Under the two mechanisms I study, the reviewer's identity is masked,
and they receive no reward for their work. Incentives or the manipulation of
incentives are thus not considered. The full model is presented in the next
section.

\section{Model} \label{sec:model}
Consider a peer review system with one journal editor and one reviewer. The
system is described as follows.
\begin{enumerate}
    \item A paper is submitted to the journal editor. It has a true quality of either low
          or high, represented by $h_i \in \set{0,1}$.
    \item The author of the paper has a binary type as well denoted by $a_i\in
              \set{o,e}$. The notation here stands for \textit{old and new} which we can
          think of as \begin{itemize}
              \item \textit{old}: more experienced, well-known in the research field
              \item \textit{new}: less experienced researchers
          \end{itemize}
    \item Having received the paper, the editor needs to make a decision on acceptance
          $\delta_i\in\set{0,1}$. He wants to accept good papers ($\delta_i=1$ when
          $h_i=1$) and reject bad papers. However, the editor does not know the true
          quality of the paper.
    \item Since she won't evaluate it herself, she delegates the referee work to a
          reviewer.
    \item The reviewer reads the paper more or less carefully by exerting some effort
          $e$. He then gives recommendations about whether to accept or reject.
    \item The reviewer can not fully discover the true quality of the paper. The
          probability that the reviewer recommends acceptance when the paper is good is
          denoted by $p_1$ and rejection when the paper is bad by $p_0$.
          \[
              \p(\delta_i = 1 \mid h_i = 1) = p_1,
          \]
          \[
              \p(\delta_i = 0 \mid h_i = 0) = p_0.
          \]
          \begin{itemize}
              \item For the editor, the higher these probabilities are, the more accurate her
                    decision is.
              \item For the reviewer, he needs to spend effort $e$ to discover the true quality
                    $h_i$. Both $p_1$ and $p_0$ increases with effort level. i.e.,
                    \[
                        \frac{\partial p_1(e)}{\partial e} > 0, \quad \frac{\partial p_0(e)}{\partial e} > 0.
                    \]
          \end{itemize}
    \item The editor follows the reviewer's recommendation exactly.
\end{enumerate}

\subsection{Reviewer}
\paragraph{Reviewer's effort} The reviewer exerts effort to review papers. The cost of effort is measured in
time, denoted by $c(e)$, with $\frac{\partial c(e)}{\partial e} > 0$.

The reviewer faces two reviewing systems $\set{\text{Double blind},\text{Single
            blind}}$. Under the double-blind system, the author's name is removed from the
paper under referee, while under single-blind, the anonymity comes from the
reviewer's side. I first discuss the two extreme cases.

In a world where the paper can stay truly anonymous in double-blind
\footnote{Non-existence of pre-print, no talk has been given etc.} the reviewer
assigns the same effort $e_b$ to every paper. Given $N$ papers, the total cost
is \[ Nc(e_b).\]

On the other hand, if reviewer can see the author's name and other information
in single-blind, I assume that in this way he knows exactly the author's type
$a_i\in \set{o,e}$. Since it is of our natural tendency to trust more
experienced people, reviewer would exert less effort checking the paper (proof,
theorem, etc.) if he knows that the author is of type $o$. Therefore, I have
\[
    e_o < e_n .
\]

If there are $k\%$ authors of type $o$, the total cost of effort is
\[
    N \pa{k c(e_o) + (1-k) c(e_n)}.
\]

It is worth mentioning that in reality however, even under double-blind, full
anonymity is often not achieved. The reviewer simply knows or can guess the
author. Let us say that $\lambda\%$ of the time reviewer still knows the
authors' type. Then the total cost is
\[
    N\bra{\lambda \big(k c(e_o) + (1-k) c(e_n)\big) + (1-\lambda) c(e_b)}.
\]
The parameter $\lambda$ measures the level of non-anonymity in a research
field. A larger $\lambda$ represents a case where it is easy for the reviewer
to find out who the author is.

\paragraph{Reviewer's indifference} Reviewer does not receive monetary award for referee work, this altruistic
action arises out of professional ethics. Meanwhile, he also faces time
constraints (e.g., own research, teaching, personal time) thus won't spend as
much effort as possible on refereeing. I assume that they assign \textbf{a
    fixed amount of time} to reviewing since there is no incentive to increase or
decrease the time spent. They are indifferent between double-blind and
single-blind because the total cost of effort is the same under the two
mechanisms, i.e.,
\[
    \lambda_{sq} \big(k c(e_o) + (1-k) c(e_n)\big) + (1-\lambda_{sq}) c(e_b) = {k c(e_o) + (1-k) c(e_n)}
\] where $\lambda_{sq}$ represents the level of non-anonymity at status quo under
double-blind system.

\paragraph{Reviewer's bias}
As mentioned before, if the reviewer knows the identity of the author, he may
exert more or less effort depending on the type. From the editor's perspective,
it is always better to have the reviewer exerts more effort by regarding the
author as type $n$. In reality, it may also introduce bias when he knows the
author's type. To be more specific, let us define a new probability
$p_1(e,a),p_0(e,a)$ which depends on the effort level of reviewer and the
reviewer's knowledge of author's type. The bias that occurred with type $o$ is
$p_0(e,o)=p_0(e)-b_o$,which translates to that condition on the paper being low
quality, the reviewer is somehow more tolerant if he knows the author is of
type $o$. While for type $e$, the bias takes place in the form of
$p_1(e,n)=p_1(e)-b_n$, which means that conditional on good paper, reviewer is
more skeptical of accepting it. All in all, I have
\[
    p_1(e,a) =
    \begin{cases}
        p_1(e)       & \text{if } a = o , \\
        p_1(e) - b_n & \text{if } a = n,
    \end{cases}
\]
\[
    p_0(e,a) =
    \begin{cases}
        p_0(e) - b_o & \text{if } a=o,    \\
        p_0(e)       & \text{if } a = n .
    \end{cases}
\]
\subsection{Editor}
\paragraph{Editor's objective}
The editor acts in the interest of the journal. She wants to accept good papers
and reject bad ones. Recall that the decision is $\delta_i$ and quality $h_i$.
There are 4 types of outcomes that can enter the editor's objective function.
\begin{table}[!htbp]
    \centering
    \begin{tabular}{c|c|c}
        \toprule
                     & $h_i=1$           & $h_i=0$               \\
        \midrule
        $\delta_i=1$ & $h_i\delta_i$     & $(1-h_i)\delta_i$     \\
        $\delta_i=0$ & $h_i(1-\delta_i)$ & $(1-h_i)(1-\delta_i)$ \\
        \bottomrule
    \end{tabular}
    \caption{}
    \label{tab:editor_objective}
\end{table}

Consider the case where the editor maximizes the number of correctly accepted
and correctly rejected paper, that is, $\sum_i h_i\delta_i$ and $\sum_i
    (1-h_i)(1-\delta_i)$. The objective function is
\begin{equation}
    \max \mathbb{E}[\sum_i \delta_i h_i] + \tau \mathbb{E}[\sum_i (1-\delta_i)(1-h_i)]
\end{equation}
which is equivalent to
\[
    \max  \set{ \p(\delta_i = 1|h_i = 1)\p(h_i = 1) +\tau \p(\delta_i = 0|h_i = 0)\p(h_i = 0)}
\]
\paragraph{Editor's payoff}
I first define some institutional setting before presenting editor's payoff
under different scenarios.
\begin{itemize}
    \item $\alpha$ is the proportion of high quality paper $\p(h_i=1)$.
    \item $\beta_o$ is the proportion of good paper from $o$ author and $\beta_n$ from $n$ author, satisfying
          \[k\beta_o+(1-k)\beta_n=\alpha\]
\end{itemize}
Now I write the editor's payoff under different scenarios.
\begin{itemize}
    \item Base case: I assume that without reading the paper, or delegating anyone to
          read the paper, the editor accepts and rejects with equal probability
          ($\p(\delta_i=1|h_i)=1/2$). \footnote{This is not saying that $\delta_i=1/2$ is
              the optimal decision rule under ignorance.} Her payoff in this case is
          \[1/2 \alpha +\tau 1/2 (1-\alpha)\]

    \item Double blind with $\lambda=0$: If the full anonymity can be achieved under
          double-blind system ($\lambda=0$), the payoff is
          \[p_1(e_b)\alpha+\tau p_0(e_b)(1-\alpha)\]
    \item Single blind with $\lambda=1$: Under single-blind, the payoff conditioning on
          the author's type $a_i$ is
          \begin{equation*}
              \begin{split}
                    & \E[\delta_i h_i+\tau(1-\delta_i)(1-h_i)|a_i]                                    \\
                  = & \p(\delta_i=1|h_i=1,a_i)\p(h_i=1|a_i)+\tau\p(\delta_i=0|h_i=0,a_i)\p(h_i=0|a_i) \\
                  = & p_1(e_a,a)\beta_a+\tau p_0(e_a,a)(1-\beta_a)
              \end{split}
          \end{equation*}
          Therefore, the total payoff is
          \[k \bra{p_1(e_o)\beta_o+\tau (p_0(e_o)-b_o)(1-\beta_o)}+(1-k)\bra{(p_1(e_n)-b_n)\beta_n+\tau p_0(e_n)(1-\beta_n)}\]
    \item Double blind with $0<\lambda<1$: the editor's payoff is a linear combination of
          the two cases above.
\end{itemize}

\subsection{Problem Formulation}
The institutional parameters are
$\set{k,\lambda_{sq},\alpha,\beta_o,\beta_n,\tau}$. The editor's preference
parameter is $\tau$ while the reviewer's bias is $\set{b_o,b_n}$. The reviewer
solves the following (indifference) problem to determine the effort level
$e_b^*,e_o^*,e_n^*$.
\begin{equation}
    \lambda_{sq} \big(k c(e_o) + (1-k) c(e_n)\big) + (1-\lambda_{sq}) c(e_b) = {k c(e_o) + (1-k) c(e_n)}
\end{equation}
Given the $e_b^*,e_o^*,e_n^*$, the editor solves the following (maximization)
problem to determine the optimal mechanism $\in
    \set{\text{double-blind},\text{single-blind}}$.
\begin{equation}
    \begin{split}\label{eq:editor}
        \max_{\lambda \in \set{\lambda_{sq},1}} & \lambda\pa{k \bra{p_1(e_o)\beta_o+\tau (p_0(e_o)-b_o)(1-\beta_o)}+(1-k)\bra{(p_1(e_n)-b_n)\beta_n+\tau p_0(e_n)(1-\beta_n)} } \\
                                                & +(1-\lambda)\pa{p_1(e_b)\alpha+\tau p_0(e_b)(1-\alpha)}                                                                       \\
    \end{split}
\end{equation}
Therefore, emulating the principal-agent problem, I write
\begin{equation}\label{eq:combined}
    \begin{split}
        \max_{\lambda \in \set{\lambda_{sq},1},e_b,e_n,e_o} & \text{editor's payoff}         \\
        \text{s.t.} \quad                                   & \text{reviewer's indifference}
    \end{split}
\end{equation}

\section{Analysis} \label{sec:analysis}
The reviewer's indifference condition simplifies to
\begin{equation*}
    c(e_b) =  k c(e_o) + (1-k) c(e_n).
\end{equation*}
Since the decision on $\lambda^*$ is binary, the editor's optimisation boils down to comparing the first and second term  in equation \ref{eq:editor}.
Rearranging the terms, I only need tocompare
\[ k\beta_o p_1(e_o) + (1-k)\beta_n p_1(e_n) + \tau(k(1-\beta_o)p_0(e_o) + (1-k)(1-\beta_n)p_0(e_n))\underbrace{-k\tau b_o(1-\beta_o) - (1-k)\tau b_n\beta_n }_{\text{bias}}\]
with \[\alpha p_1(e_b) + \tau(1-\alpha)p_0(e_b).\]
I first make comparison without taking into account the bias term.
\paragraph{Linear case} Starting with the simplest, I assume that $c(e)=p_1(e)=p_0(e)=e$. Comparing
$k\beta_o p_1(e_o) + (1-k)\beta_n p_1(e_n)$ and $\alpha p_1(e_b)$ boils down to
\begin{equation*}
    \begin{bmatrix}
        k\beta_o & (1-k)\beta_n
    \end{bmatrix}
    \pa{
        \begin{bmatrix}
            e_0 \\ e_n
        \end{bmatrix}
        -
        \begin{bmatrix}
            1 \\ 1
        \end{bmatrix}
        \begin{bmatrix}
            k & 1-k
        \end{bmatrix}
        \begin{bmatrix}
            e_0 \\ e_n
        \end{bmatrix}}
    \stackrel{?}{\leq} 0
\end{equation*}
% \begin{equation*}
%     \begin{bmatrix}
%         \alpha_1 & \alpha_2
%     \end{bmatrix}
%     \pa{
%         \begin{bmatrix}
%             1-k & k-1 \\
%             -k  & k
%         \end{bmatrix}
%         \begin{bmatrix}
%             e_o \\ e_n
%         \end{bmatrix}}
%     \stackrel{?}{\geq} 0
% \end{equation*}
% \begin{equation*}
%     \begin{bmatrix}
%         \alpha_1 & \alpha_2
%     \end{bmatrix}

%     \begin{bmatrix}
%         k-1 \\
%         k
%     \end{bmatrix}
%     (e_n-e_o)
%     \stackrel{?}{\geq} 0
% \end{equation*}
\begin{equation*}
    k\beta_o (k-1)+(1-k)\beta_n k  \Leftrightarrow \beta_n-\beta_o \stackrel{?}{\leq} 0.
\end{equation*}
By definition $\beta_n<\beta_o$, which implies that the second term is larger than the first term even without bias. Adding back the bias, editor prefers double-blind undoubtedly.

\paragraph{General case} My intuition is that if $c''(e)>p''(e) \ \forall e$, then even without the
bias, the editor prefers double-blind mechanism. To begin with, I take $p(e)=e$
and $c(e)=1/2e^2$. I can write the condition as
\begin{equation*}
    \begin{bmatrix}
        k\beta_o & (1-k)\beta_n
    \end{bmatrix}
    \pa{
        \begin{bmatrix}
            p(e_0) \\ p(e_n)
        \end{bmatrix}
        -
        \begin{bmatrix}
            1 \\ 1
        \end{bmatrix}
        p(e_b)}
    \stackrel{?}{\leq} 0
\end{equation*}
while
\[e_b^2 = k e_o^2 + (1-k)e_n^2 \Leftrightarrow e_b = k^* e_o + (1-k^*)e_n \text{ for some } k^*<k\]
The condition is more negative in this case.
\begin{equation*}
    k\beta_o (k^*-1)+(1-k)\beta_n k^* < \beta_n-\beta_o< 0.
\end{equation*}

Now I assume that $c(x)=\log(x+1)$ and $p(x)=x$, then the fact that $e_b = k^*
    e_o + (1-k^*)e_n \text{ for some } k^*>k$ implies that the condition $k\beta_o
    (k^*-1)+(1-k)\beta_n k^*$ is ambiguous. If $\beta_n$ is not too small compared
to $\beta_o$ (the proportion of good paper from $n$ author is not that
different from $o$ author), and the bias $b_o, b_n$ not too large, then it is
possible that the editor prefers single-blind mechanism with $\lambda=1$.
\begin{proposition}
    If $c''(e)\ge p''(e)$ for all $e$, the editor always prefers double-blind mechanism subject to a status quo level of anonymity $\lambda_{sq}$. When it is not the case and that the author's productivity difference, reviewer's bias are not too large, editor may prefer single-blind mechanism.
\end{proposition}

While I was expecting that the status quo anonymity
$\lambda_{sq}$\footnote{i.e., how difficult it is for the paper to be truly
    blind} would play a role in the editor's decision $\lambda \in
    \set{\lambda_{sq},1}$, it turns out that it doesn't matter at all under the
model I set up. This is a question to be investigated in the next section.

\section{Discussion}
In this section, I discuss several aspects of the model that I have thought
about but ignored in the previous section.
\paragraph{Non-anonymity level $\lambda_{sq}$} Several papers have provided
evidence that for some research field, there's no point bothering with
double-blind. Because reviewers are assigned papers in their respective fields,
chances are that they have already seen the work as preprint in archive,
working paper or attended the author's talk themselves. This is especially true
if the field is niche. This evidence suggests that intuitively speaking, a
higher level of $\lambda_{sq}$ should favor single-blind.

As discussed in section \ref{sec:analysis}, the editor chooses double-blind for
sure if full anonymity gives a higher payoff than full-disclosure. However,
even under double-blind, full anonymity is not achieved because there exists an
inherent non-anonymity level $\lambda_{sq}$ for each research field. All other
things being equal, a research field where it is easier for papers to stay
truly blind (low $\lambda_{sq}$) should more likely end up in a double-blind
system than a field where everyone knows everyone (high $\lambda_{sq}$). To
incorporate the idea into a model, I should introduce a fixed cost $c$ for the
editor if she implements a double-blind mechanism. The fixed cost spent in
anonymizing papers\footnote{This is more than just removing names but also
    verifying if there's any revealing information in the paper} is the same for
every field. Therefore, even if
\begin{equation*}
    \begin{split}
        \alpha p_1(e_b) + \tau(1-\alpha)p_0(e_b)> &
        k\beta_o p_1(e_o) + (1-k)\beta_n p_1(e_n)   \\ & + \tau(k(1-\beta_o)p_0(e_o) + (1-k)(1-\beta_n)p_0(e_n))\\
                                                  &
        \underbrace{-k\tau b_o(1-\beta_o) - (1-k)\tau b_n\beta_n }_{\text{bias}}
    \end{split}
\end{equation*}
the anonymization cost may be too large to make double-blinding beneficial if the weight $(1-\lambda_{sq})$ on the larger term $\alpha p_1(e_b) + \tau(1-\alpha)p_0(e_b)>$ is small.
By incorporating a fixed anonymization cost, the editor's choice of mechanism will depend on the status quo non-anonymity level $\lambda_{sq}$ (as I wish).

\paragraph{Reviewer's indifference condition} I have assumed reviewer is indifferent between the two mechanism since they do
not get compensation or reward for their time spent, as in reality. This
indifference condition serves as a constraint in the combined problem
\ref{eq:combined}. However, I argue that this condition is not enough to pin
down the effort level $(e_b, e_o, e_n)$ given all the parameters specified
before. Because for either $\lambda\in \set{\lambda_{sq},1}$ the editor's
payoff is maximized when effort is as high as possible. Yet there's no
constraint on the upper bound of $c(e)$. It should be imposed e.g.,
$kc(e_o)+(1-k)(e_n)<\bar{c}$ so that all decision variable $\lambda, e_b, e_o,
    e_n$ can be pinned down.

Another extension is to introduce reviewer's incentive in their effort
decision. Currently, since both mechanism \textit{blind} reviewer's identity
such that they only get "We thank the anonymized reviewers for their helpful
feedback." as reward. It would be interesting to think about rewarding reviewer
in a non-pecuniary way. Propositions include credit system, promotion scheme
etc. Or we can imagine a world where there's openness to the reviewer's
feedback or even revelation of his identity. If reviewer is incentivized in
some ways, the original question would take on the flavor of the classical
principal-agent problem. In this case, the editor (principal) will juggle
between many things in her choice of mechanism.

\paragraph{Editor's objective function}
I have briefly alluded to the 4 types of editor's concern as in table
\ref{tab:editor_objective}. Intuitively, the editor wants to maximize diagonal
terms and minimized the off-diagonal ones. I argue that it is enough to take 2
out of 4 such that the there exists a countervailing pair $h_i\delta_i$ and
$-\delta_i$.\footnote{By labeling the element in the table horizontally, I can
    take $(1,2),(1,4),(2,4),(2,3),(4,3)$. Taking only $4$ also works if I treat the
    two forces (accept good and reject bad) equally.} \pagebreak \newpage
\bibliography{../References/ref.bib}

\end{document}